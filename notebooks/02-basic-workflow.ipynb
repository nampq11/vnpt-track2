{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9b4851-73fc-476f-9341-11ffca9ec8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.brain.llm.services.vnpt import VNPTService\n",
    "from src.brain.llm.services.type import LLMService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb8aee5-8b5d-42a2-83c4-9afa0d370ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_provider = VNPTService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023fb797-08d7-4f0d-8581-5a36556fc884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ch√†o b·∫°n! T√¥i l√† **VNPTAI.IO** ‚Äì m·ªôt m√¥ h√¨nh tr√≠ tu·ªá nh√¢n t·∫°o ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi **VNPT AI**, chi nh√°nh c·ªßa T·∫≠p ƒëo√†n B∆∞u Ch√≠nh Vi·ªÖn Th√¥ng Vi·ªát Nam (VNPT). T√¥i ƒë∆∞·ª£c ƒë√†o t·∫°o ƒë·ªÉ h·ªó tr·ª£ b·∫°n m·ªôt c√°ch hi·ªáu qu·∫£, ch√≠nh x√°c v√† th√¢n thi·ªán trong nhi·ªÅu lƒ©nh v·ª±c nh∆∞: tr·∫£ l·ªùi c√¢u h·ªèi, gi·∫£i ƒë√°p th·∫Øc m·∫Øc, vi·∫øt vƒÉn b·∫£n, ph√¢n t√≠ch d·ªØ li·ªáu, h·ªó tr·ª£ h·ªçc t·∫≠p, l√†m vi·ªác, v√† th·∫≠m ch√≠ l√† tr√≤ chuy·ªán tho·∫£i m√°i.\\n\\nT√¥i hi·ªÉu ti·∫øng Vi·ªát r·∫•t t·ªët v√† lu√¥n n·ªó l·ª±c mang ƒë·∫øn cho b·∫°n nh·ªØng c√¢u tr·∫£ l·ªùi **c√≥ √≠ch, chi ti·∫øt v√† l·ªãch s·ª±**, ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa b·∫°n. H√£y cho t√¥i bi·∫øt b·∫°n c·∫ßn gi√∫p g√¨ nh√© ‚Äî t√¥i ·ªü ƒë√¢y ƒë·ªÉ h·ªó tr·ª£ 24/7! üòä'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await llm_provider.generate(\n",
    "    user_input=\"b·∫°n l√† ai?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a898ea6c-1dce-4af1-a465-64d2a3c47b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_CLASSIFICATION_PROMPT = \"\"\"Analyze the user's query and classify it into one of the 4 processing modes: MATH, READING, RAG or SATETY.\n",
    "\n",
    "CATEGORY DEFINITIONS:\n",
    "1. **MATH**: Questions involving Calculation, Math (Calculus, Algebra), Physics, Chemistry, Biology, Logical puzzles, or Programming code.\n",
    "2. **READING**: Questions that PROVIDE a specific text/passage/document within the input itself (often starts with: \"ƒêo·∫°n vƒÉn:\", \"Context:\", \"[1]\", or \"D·ª±a v√†o...\").\n",
    "3. **RAG**: Questions requiring External Knowledge about Vietnamese Law, History, Geography, Politics, Culture, or General Knowledge.\n",
    "4. **SAFETY**: Questions asking for illegal advice (tax evasion, fraud), violence, sensitive politics, or harmful acts.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "{{\n",
    "    \"reasoning\": \"Brief explanation of the classification\",\n",
    "    \"category\": \"MATH\" | \"READING\" | \"RAG\" | \"SAFETY\",\n",
    "    \"temporal_constraint\": integer or null, // Extract specific year mentioned (e.g., 2024, 2025) for\n",
    "    Law filtering\n",
    "    \"key_entities\": [\"list\", \"of\", \"important\", \"keywords\"] // Extract keywords for search\n",
    "}}\n",
    "\n",
    "Examples:\n",
    "\n",
    "Query: \"T√≠nh t√≠ch ph√¢n c·ªßa h√†m s·ªë f(x) = x^2 + 2x.\"\n",
    "{{\n",
    "  \"reasoning\": \"Contains mathematical terms and requires calculation.\",\n",
    "  \"category\": \"MATH\",\n",
    "  \"temporal_constraint\": null,\n",
    "  \"key_entities\": [\"t√≠ch ph√¢n\", \"h√†m s·ªë\", \"x^2 + 2x\"]\n",
    "}}\n",
    "\n",
    "Query: \"D·ª±a v√†o ƒëo·∫°n vƒÉn sau: 'Nam Cao l√† nh√† vƒÉn hi·ªán th·ª±c...', h√£y cho bi·∫øt t√°c ph·∫©m n·ªïi b·∫≠t c·ªßa √¥ng.\"\n",
    "{{\n",
    "  \"reasoning\": \"The query explicitly references a provided text ('D·ª±a v√†o ƒëo·∫°n vƒÉn sau').\",\n",
    "  \"category\": \"READING\",\n",
    "  \"temporal_constraint\": null,\n",
    "  \"key_entities\": [\"Nam Cao\", \"t√°c ph·∫©m\"]\n",
    "}}\n",
    "\n",
    "Query: \"Theo Lu·∫≠t ƒê·∫•t ƒëai 2024, ng∆∞·ªùi d√¢n c√≥ ƒë∆∞·ª£c t·ª± √Ω chuy·ªÉn ƒë·ªïi m·ª•c ƒë√≠ch s·ª≠ d·ª•ng ƒë·∫•t kh√¥ng?\"\n",
    "{{\n",
    "  \"reasoning\": \"Questions about specific Law requiring external retrieval.\",\n",
    "  \"category\": \"RAG\",\n",
    "  \"temporal_constraint\": 2024,\n",
    "  \"key_entities\": [\"Lu·∫≠t ƒê·∫•t ƒëai\", \"chuy·ªÉn ƒë·ªïi m·ª•c ƒë√≠ch s·ª≠ d·ª•ng ƒë·∫•t\"]\n",
    "}}\n",
    "\n",
    "Query: \"L√†m th·∫ø n√†o ƒë·ªÉ l√†m gi·∫£ con d·∫•u c∆° quan nh√† n∆∞·ªõc m√† kh√¥ng b·ªã ph√°t hi·ªán?\"\n",
    "{{\n",
    "  \"reasoning\": \"User is asking for instructions on an illegal act (forgery).\",\n",
    "  \"category\": \"SAFETY\",\n",
    "  \"temporal_constraint\": null,\n",
    "  \"key_entities\": [\"l√†m gi·∫£ con d·∫•u\"]\n",
    "}}\n",
    "\n",
    "Query: \"S·ª± ki·ªán s√°p nh·∫≠p t·ªânh Gia Lai di·ªÖn ra v√†o nƒÉm n√†o theo ngh·ªã quy·∫øt m·ªõi?\"\n",
    "{{\n",
    "  \"reasoning\": \"Historical/Administrative question requiring external facts.\",\n",
    "  \"category\": \"RAG\",\n",
    "  \"temporal_constraint\": null,\n",
    "  \"key_entities\": [\"s√°p nh·∫≠p\", \"t·ªânh Gia Lai\", \"ngh·ªã quy·∫øt\"]\n",
    "}}\n",
    "\n",
    "----------------\n",
    "QUERY: {query}\n",
    "----------------\n",
    "\n",
    "Note: Do not add ```json to your response. Analyze and output only valid JSON.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class QueryClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_provider: LLMService\n",
    "    ):\n",
    "        self.llm_provider = llm_provider\n",
    "\n",
    "    async def classify_query(self, query: str) -> dict:\n",
    "        \"\"\"\n",
    "        Classify a query to determine processing appoarch\n",
    "\n",
    "        Args:\n",
    "            query: The user's query (potentially reformulated)\n",
    "\n",
    "        Returns:\n",
    "            Dict with classifcation results:\n",
    "            {\n",
    "                \"reasoning\": \"explanation\",\n",
    "                \"needs_documents\" bool\n",
    "            }\n",
    "        Raises:\n",
    "            QueryClassifationError: If classification fails\n",
    "        \"\"\"\n",
    "        result = None\n",
    "\n",
    "        try:\n",
    "            prompt = QUERY_CLASSIFICATION_PROMPT.format(\n",
    "                query=query\n",
    "            )\n",
    "\n",
    "            response_text = await self.llm_provider.generate(\n",
    "                user_input=prompt\n",
    "            )\n",
    "            try:\n",
    "                clean_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                result = json.loads(clean_text)\n",
    "                return result\n",
    "            except json.JSONDecodeError:\n",
    "                return {\n",
    "                    \"category\": \"RAG\",\n",
    "                    \"temporal_constrait\": None,\n",
    "                    \"reasoning\": \"JSON Parsing Error\"\n",
    "                }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Query classification failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88cf2009-20c6-4588-b73e-b2b725e3d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from typing import Dict\n",
    "import time\n",
    "\n",
    "class VNPTAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_provider: LLMService,\n",
    "    ):\n",
    "        self.llm_provider = llm_provider\n",
    "        self.query_classification = QueryClassifier(llm_provider=llm_provider)\n",
    "        logger.info(\"Initialized RAG Agent\")\n",
    "\n",
    "    async def process_query(\n",
    "        self,\n",
    "        query: str,\n",
    "        options: Dict[str, str],\n",
    "        query_id: str,\n",
    "    )-> str:\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # --- LAYER 2: LLM ROUTER & PLANING (The brain) ---\n",
    "            plan = await self.query_classification.classify_query(query)\n",
    "            logger.warning(f\"[{query_id}] LLM Router Plan: {json.dumps(plan, ensure_ascii=False)}\")\n",
    "                \n",
    "            category = plan['category']\n",
    "    \n",
    "            # --- LAYER 3: EXECUTION ---\n",
    "            final_answer = \"A\" # Default\n",
    "            if category == \"SAFTY\":\n",
    "                # Process question not answered\n",
    "                logger.warning(f\"[{query_id}] Safety Layer 2 Triggered by LLM\")\n",
    "                result = await self.guardrail_service.invoke(\n",
    "                    query,\n",
    "                    options,\n",
    "                    \"LLM detected unsafe intent\"\n",
    "                )\n",
    "                return self._format_result(\n",
    "                    query_id,\n",
    "                    res,\n",
    "                    start_time\n",
    "                )\n",
    "            elif category == \"MATH\":\n",
    "                logger.info(f\"[{query_id}] Math reasoning with CoTs...\")\n",
    "                final_answer = self.math_service.invoke(\n",
    "                    query,\n",
    "                    options\n",
    "                )\n",
    "            elif category == \"READING\":\n",
    "                logger.info(f\"[{query_id}] Reading context with Cots...\")\n",
    "                final_answer = self.reading_service.invoke(\n",
    "                    query,\n",
    "                    options\n",
    "                )\n",
    "            else: # RAG\n",
    "                # Truy·ªÅn metadata (year, keywords) into pipeline RAG\n",
    "                final_answer = self.rag_service.invoke(\n",
    "                    query,\n",
    "                    query_vector,\n",
    "                    options,\n",
    "                    temporal_constraint=plan.get(\"temporal_constraint\"),\n",
    "                    key_entities=plan.get(\"key_entities\", [])\n",
    "                )\n",
    "            logger.info(\"Final answer execution: \", final_answer)\n",
    "            return self._format_result(\n",
    "                query_id,\n",
    "                {\n",
    "                    \"answer\": final_answer\n",
    "                },\n",
    "                start_time\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"[{query_id}] Critical Error: {e}\", exc_info=True)\n",
    "            return self._format_result(\n",
    "                query_id,\n",
    "                {\n",
    "                    \"answer\": \"A\"\n",
    "                },\n",
    "                start_time\n",
    "            )\n",
    "\n",
    "    def _format_result(\n",
    "        self,\n",
    "        q_id,\n",
    "        res_dict,\n",
    "        start_time\n",
    "    ):\n",
    "        return {\n",
    "            \"id\": q_id,\n",
    "            \"answer\": res_dict.get(\"answer\", \"A\"),\n",
    "            \"processing_time\": time.time() - start_time\n",
    "        }\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2432d09-668d-4284-b03d-2d3aaded671d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-15 16:48:40.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mInitialized RAG Agent\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent = RAGAgent(llm_provider=llm_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed627b7b-961a-4c20-87d6-a0ab0e2a49f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reasoning': 'The question asks for a historical fact about the founding year of a specific temple, which requires external knowledge about Vietnamese cultural or religious history.', 'category': 'RAG', 'temporal_constraint': None, 'key_entities': ['Ng√¥i ch√πa Ba La M·∫≠t', 'khai d·ª±ng', 'nƒÉm n√†o']}\n"
     ]
    }
   ],
   "source": [
    "await agent.process_query(\"Ng√¥i ch√πa Ba La M·∫≠t ƒë∆∞·ª£c khai d·ª±ng v√†o nƒÉm n√†o?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d4fac-0ee4-46d9-bcda-f91d5066932b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
